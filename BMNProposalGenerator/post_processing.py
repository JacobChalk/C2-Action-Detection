# -*- coding: utf-8 -*-
import numpy as np
import pandas as pd
import json
import multiprocessing as mp
from os.path import join
from datetime import timedelta

from utils import iou_with_anchors


def load_json(file):
    with open(file) as json_file:
        data = json.load(json_file)
        return data


def getDatasetDict(opt):
    df = pd.read_csv(opt["video_info"])
    json_data = load_json(opt["video_anno"])
    database = json_data
    video_dict = {}
    for i in range(len(df)):
        video_name = df.video.values[i]
        video_info = database[video_name]
        video_new_info = {}
        video_new_info['duration_frame'] = video_info['duration_frame']
        video_new_info['duration_second'] = video_info['duration_second']
        video_new_info["feature_frame"] = video_info['feature_frame']
        video_subset = df.subset.values[i]
        video_new_info['annotations'] = video_info['annotations']
        if video_subset == 'validation':
            video_dict[video_name] = video_new_info
    return video_dict


def soft_nms(df, alpha, t1, t2, opt):
    '''
    df: proposals generated by network;
    alpha: alpha value of Gaussian decaying function;
    t1, t2: threshold for soft nms.
    '''
    df = df.sort_values(by="score", ascending=False)
    tstart = list(df.xmin.values[:])
    tend = list(df.xmax.values[:])
    tscore = list(df.score.values[:])

    rstart = []
    rend = []
    rscore = []

    while len(tscore) > 1 and len(rscore) < opt['post_processing_topk']+1:
        max_index = tscore.index(max(tscore))
        tmp_iou_list = iou_with_anchors(
            np.array(tstart),
            np.array(tend), tstart[max_index], tend[max_index])
        for idx in range(0, len(tscore)):
            if idx != max_index:
                tmp_iou = tmp_iou_list[idx]
                tmp_width = tend[max_index] - tstart[max_index]
                if tmp_iou > t1 + (t2 - t1) * tmp_width:
                    tscore[idx] = tscore[idx] * np.exp(-np.square(tmp_iou) /
                                                       alpha)

        rstart.append(tstart[max_index])
        rend.append(tend[max_index])
        rscore.append(tscore[max_index])
        tstart.pop(max_index)
        tend.pop(max_index)
        tscore.pop(max_index)

    newDf = pd.DataFrame()
    newDf['score'] = rscore
    newDf['xmin'] = rstart
    newDf['xmax'] = rend
    return newDf

def video_post_process(opt, video_list, annotations, lengths):
    count=0
    for video_name in video_list:
        count+=1
        print(f"Postprocessing {count}/{len(video_list)}")
        df = pd.read_csv(opt['output_path']+"/BMN_results/" + video_name + ".csv")

        proposals_per_minute = opt['ppm']
        opt['post_processing_topk'] = int(lengths[video_name]/opt['fps']/60*proposals_per_minute)

        if len(df) > 1:
            snms_alpha = opt["soft_nms_alpha"]
            snms_t1 = opt["soft_nms_low_thres"]
            snms_t2 = opt["soft_nms_high_thres"]
            df = soft_nms(df, snms_alpha, snms_t1, snms_t2, opt)

        df = df.sort_values(by="score", ascending=False)
        duration_second = lengths[video_name]/opt['fps']
        video_duration = duration_second
        proposal_list = []

        for j in range(min(opt['post_processing_topk'], len(df))):
            tmp_proposal = {}
            tmp_proposal["score"] = df.score.values[j]
            tmp_proposal["segment"] = [max(0, df.xmin.values[j]) * video_duration,
                                           min(1, df.xmax.values[j]) * video_duration]
            proposal_list.append(tmp_proposal)
        result_dict[video_name] = proposal_list


def s2t(t):
    r = str(timedelta(seconds=t))
    if '.' in r:
        r = r[:-4]
    else:
        r+='.00'
    return r


def BMN_post_processing(opt):
    sset = 'test_timestamps' if opt['inference_set'] == 'test' else opt['inference_set']
    annotations = pd.read_csv(join(opt["path_to_dataset"], sset + '.csv'),
                                   names=['id', 'video', 'start', 'stop', 'verb', 'noun', 'action'], index_col='id')

    if isinstance(annotations.iloc[0]['start'], str):
        annotations = pd.read_csv(join(opt["path_to_dataset"], sset + '.csv'), index_col='narration_id')

    video_list = [v.strip() for v in annotations['video'].unique()]
    lengths = pd.read_csv(join(opt["path_to_dataset"], 'video_lengths.csv'))
    length_dict = lengths.set_index('video').to_dict()['frames']
    global result_dict
    result_dict = mp.Manager().dict()

    num_videos = len(video_list)
    num_videos_per_thread = num_videos // opt["post_process_thread"]
    processes = []
    for tid in range(opt["post_process_thread"] - 1):
        tmp_video_list = video_list[tid * num_videos_per_thread:(tid + 1) * num_videos_per_thread]
        p = mp.Process(target=video_post_process, args=(opt, tmp_video_list, annotations, length_dict))
        p.start()
        processes.append(p)
    tmp_video_list = video_list[(opt["post_process_thread"] - 1) * num_videos_per_thread:]
    p = mp.Process(target=video_post_process, args=(opt, tmp_video_list, annotations, length_dict))
    p.start()
    processes.append(p)
    for p in processes:
        p.join()

    result_dict = dict(result_dict)

    l_narration_id = []
    l_participant_id = []
    l_video_id = []
    l_start_seconds = []
    l_stop_seconds = []
    l_start_frame = []
    l_stop_frame = []
    l_score = []
    l_start_timestamps = []
    l_stop_timestamps = []



    for vid, records in result_dict.items():
        proposal_id = 0
        for record in records:
            participant_id = vid.split('_')[0]
            video_id = vid
            segment = record['segment']
            fps = 50 if len(video_id.split('_')[1]) == 3 else 60
            start_frame = int(segment[0] * fps + 1)
            stop_frame = int(segment[1] * fps + 1)
            l_narration_id.append(f"{video_id}_{proposal_id}")
            l_participant_id.append(participant_id)
            l_video_id.append(video_id)
            l_start_seconds.append(segment[0])
            l_stop_seconds.append(segment[1])
            l_start_timestamps.append(s2t(segment[0]))
            l_stop_timestamps.append(s2t(segment[1]))
            l_start_frame.append(start_frame)
            l_stop_frame.append(stop_frame)
            l_score.append(record['score'])
            proposal_id += 1

    ts = pd.DataFrame({
        'narration_id': l_narration_id,
        'participant_id': l_participant_id,
        'video_id': l_video_id,
        'start_seconds': l_start_seconds,
        'stop_seconds': l_stop_seconds,
        'start_timestamp': l_start_timestamps,
        'stop_timestamp': l_stop_timestamps,
        'start_frame': l_start_frame,
        'stop_frame': l_stop_frame,
        'score': l_score
    }).set_index('narration_id')

    if opt['inference_set']=='validation':
        ts.to_pickle(opt['output_path']+'/'+opt["result_file"].replace('.pkl','-validation.pkl'))
    elif opt['inference_set'] == 'test_supp':
        ts.to_pickle(opt['output_path']+'/'+opt["result_file"].replace('.pkl','-supp.pkl'))
    else:
        ts.to_pickle(opt['output_path']+'/'+opt["result_file"].replace('.pkl','-test.pkl'))

    """output_dict = {"results": result_dict}
    if opt['inference_set']=='validation':
        outfile = open(opt['output_path']+'/'+opt["result_file"].replace('.json','-validation.json'), "w")
    elif opt['inference_set'] == 'test_supp':
        outfile = open(opt['output_path']+'/'+opt["result_file"].replace('.json','-supp.json'), "w")
    else:
        outfile = open(opt['output_path']+'/'+opt["result_file"].replace('.json','-test.json'), "w")

    json.dump(output_dict, outfile)
    outfile.close()"""

